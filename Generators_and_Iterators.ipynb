{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting blosc\n",
      "Installing collected packages: blosc\n",
      "Successfully installed blosc-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install blosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import blosc\n",
    "import pickle\n",
    "from numpy import genfromtxt\n",
    "import zmq\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_and_pickle(obj, flags=0, protocol=-1):\n",
    "    \"\"\"pickle an object, and zip the pickle before sending it\"\"\"\n",
    "    p = pickle.dumps(obj, protocol)\n",
    "    z = blosc.compress(p, typesize=8)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now this is only to get rows to be classified, not trained (with partial fit)\n",
    "class Chunk_Generator(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_file_details(self, meas, exp, user):\n",
    "        self.meas = meas\n",
    "        self.exp = exp\n",
    "        self.user = user\n",
    "        \n",
    "    def getrows(self, chunkrows):\n",
    "        delimiter = \" \"\n",
    "        header_names = [\"x\", \"y\", \"z\"]\n",
    "        \n",
    "        data_folder = 'data/raw_data'\n",
    "        if int(self.exp) < 10:\n",
    "            self.exp = str(self.exp).zfill(2)\n",
    "        \n",
    "        if int(self.user) < 10:\n",
    "            self.user = str(self.user).zfill(2)\n",
    "            \n",
    "        if self.meas == 'both':\n",
    "            filename = \"acc_exp\" + self.exp + \"_user\" + self.user + \".txt\"\n",
    "            path = data_folder + '/' + filename\n",
    "            acc_data = genfromtxt(path, delimiter=' ')\n",
    "            \n",
    "            filename = \"gyro_exp\" + self.exp + \"_user\" + self.user + \".txt\"\n",
    "            path = data_folder + '/' + filename\n",
    "            gyro_data = genfromtxt(path, delimiter=' ')\n",
    "            return (acc_data[chunkrows], gyro_data[chunkrows])\n",
    "        else:\n",
    "            filename = self.meas + \"_exp\" + self.exp + \"_user\" + self.user + \".txt\"\n",
    "            path = data_folder + '/' + filename\n",
    "            data = genfromtxt(path, delimiter=' ')\n",
    "            return data[chunkrows]\n",
    "    \n",
    "    def iter_minibatches(self, chunksize, numtrainingpoints):\n",
    "        # Provide chunks one by one\n",
    "        chunkstartmarker = 0\n",
    "        while chunkstartmarker < numtrainingpoints:\n",
    "            chunkrows = range(chunkstartmarker, chunkstartmarker+chunksize)\n",
    "            X_chunk = self.getrows(chunkrows)\n",
    "#             print(np.average(X_chunk))\n",
    "            yield X_chunk\n",
    "            chunkstartmarker += chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data/raw_data'\n",
    "\n",
    "# path joining version for other paths\n",
    "no_of_files = (len([name for name in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, name))]))\n",
    "print(no_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(sorted(os.listdir(data_folder))):\n",
    "#     print(i, filename)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.91805559 -0.1125      0.50972225]\n",
      " [ 0.91111113 -0.09305556  0.53750004]\n",
      " [ 0.8819445  -0.08611111  0.51388893]\n",
      " [ 0.8819445  -0.08611111  0.51388893]\n",
      " [ 0.87916671 -0.1         0.50555558]\n",
      " [ 0.88888896 -0.10555556  0.51250004]\n",
      " [ 0.86250001 -0.10138889  0.50972225]\n",
      " [ 0.86111112 -0.10416667  0.5013889 ]\n",
      " [ 0.85416666 -0.10833334  0.5277778 ]\n",
      " [ 0.85138888 -0.10138889  0.5527778 ]]\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data/raw_data'\n",
    "filename = \"acc_exp01_user01.txt\"\n",
    "path = data_folder + '/' + filename\n",
    "\n",
    "my_data = genfromtxt(path, delimiter=' ')\n",
    "print(my_data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = Chunk_Generator()\n",
    "cg.set_file_details('acc', 1, 1)\n",
    "\n",
    "batcherator = cg.iter_minibatches(chunksize=10, numtrainingpoints=100)\n",
    "aggregate = []\n",
    "for X_chunk in batcherator:\n",
    "#     print(X_chunk)\n",
    "    aggregate.extend(X_chunk.tolist())\n",
    "\n",
    "# print(aggregate)\n",
    "    \n",
    "# if np.equal(aggregate, my_data[0:100]).all():\n",
    "#     print(\"Equal\")\n",
    "# else:\n",
    "#     print(\"Not equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZMQ_HOST = 'localhost'\n",
    "ZMQ_PORT = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Client-001'\n"
     ]
    }
   ],
   "source": [
    "socket = zmq.Context().socket(zmq.DEALER)\n",
    "ident = str(random.randint(1, 5)).zfill(3)\n",
    "socket.identity = u\"Client-{}\".format(ident).encode(\"ascii\")\n",
    "socket.connect(\"tcp://{}:{}\".format(ZMQ_HOST, ZMQ_PORT))\n",
    "print(socket.identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda x: x.decode('utf-8')\n",
    "encode = lambda x: x.encode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas = 'both'\n",
    "cg = Chunk_Generator()\n",
    "cg.set_file_details(meas, 1, 1)\n",
    "\n",
    "batcherator = cg.iter_minibatches(chunksize=550, numtrainingpoints=20000)\n",
    "aggregate = []\n",
    "\n",
    "    \n",
    "if meas == 'both':\n",
    "    for acc_chunk, gyro_chunk in batcherator:\n",
    "    #     aggregate.extend(X_chunk.tolist())\n",
    "        dict_req = {}\n",
    "\n",
    "        dict_req[\"sender\"] = socket.identity.decode('ascii')\n",
    "        dict_req[\"command\"] = \"CLASSIFY\"\n",
    "        dict_req[\"database\"] = meas\n",
    "        dict_req = encode(json.dumps(dict_req))\n",
    "\n",
    "        pickled_acc_chunk = zip_and_pickle(acc_chunk)\n",
    "        pickled_gyro_chunk = zip_and_pickle(gyro_chunk)\n",
    "\n",
    "        request = [dict_req, pickled_acc_chunk, pickled_gyro_chunk]\n",
    "        message = socket.send_multipart(request)\n",
    "else:\n",
    "    for X_chunk in batcherator:\n",
    "    #     aggregate.extend(X_chunk.tolist())\n",
    "        dict_req = {}\n",
    " \n",
    "        dict_req[\"sender\"] = socket.identity.decode('ascii')\n",
    "        dict_req[\"command\"] = \"CLASSIFY\"\n",
    "        dict_req[\"database\"] = meas\n",
    "        dict_req = encode(json.dumps(dict_req))\n",
    "\n",
    "        pickled_chunk = zip_and_pickle(X_chunk)\n",
    "\n",
    "        request = [dict_req, pickled_chunk]\n",
    "        message = socket.send_multipart(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
